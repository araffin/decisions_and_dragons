<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>About | Decisions &amp; Dragons</title>
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="stylesheet" href="/css/fonts.css">
    <link rel="stylesheet" href="/css/home.css">
    <link rel="stylesheet" href="/css/page_without_toc.css">
    <link rel="stylesheet" href="/css/page_with_toc.css">
    <link rel="stylesheet" href="/css/content_structure.css">
    <link rel="stylesheet" href="/css/mdx.css">


      <script src="/js/main.js"></script>


  
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']] , 
      tags: 'ams'
    }
  };
</script>
  
  <script>
window.addEventListener("hashchange", function () {
    window.scrollTo(window.scrollX, window.scrollY - 70);
});
</script>
</head>
<body>
    
<div id="small_splash">
    <span
        ><a class="logo_link" href="http://localhost:1313/"
            >Decisions &amp; Dragons</a
        ></span
    >
    <span class="nav">
        
        <a href=" /">Home</a>
        
        <a href=" /about/">About</a>
        
        <a href=" /posts/">All posts</a>
        
        <a href=" /notation/">Notaiton</a>
        
        <a href=" https://twitter.com/jmac_ai">Twitter</a>
        
    </span>
</div>


    
  <div id="content_no_toc">
    <h1>About</h1>
    <p>Reinforcement learning (RL) is an elegant problem definition for autonomous agents that learn
from their own interactions with an environment. But the methods to solve this simple problem definition are not so simple. To solve this problem you must simultaneously tackle many subproblems that are all complex enough to warrant their own subfields in AI, such as perception, prediction, planning, and memory.</p>
<p>Furthermore, unlike other forms of machine learning, an RL algorithm is not provided well-curated datasets. An RL agent must form its own data from interactions. Even worse, the data the agent collects does not explicitly include the correct response in it and it is highly correlated. Instead, an RL agent must reason about its data to determine the correct reponse and it must actively explore the environment to ensure it has good data coverage. And if that wasn&rsquo;t hard enough for you, solving this problem often involves learning multiple interacting models, instead of just one.</p>
<p>The RL problem is <em>hard</em> and if you feel lost trying to grock it, you&rsquo;re not alone.</p>
<p>Although I now feel comfortable in the field, it took me a long time to feel that way. I overcame my struggles with reinforcement learning by building my understanding from fundamental principles. Over the years, I&rsquo;ve done what I can to help others understand some of the paritcularly elusive concepts in this field. During that time, I&rsquo;ve found that certain questions get asked more than others and I&rsquo;ll often point people to different places where I&rsquo;ve already answered that question. However, my answers are often scattered over many different platforms and the format of those platforms were not always conducive to providing the presentation the answer deserves.</p>
<p>This website aims to address those problems. Here I&rsquo;ve collected answers I&rsquo;ve given to common questions in the past and expanded on them.</p>
<p>Each answer begins with a concise response, followed by a step-by-step derivation from first principles. The aim of these step-by-step derivations is to fill in the gaps commonly skipped over in papers where people usually get stuck.</p>
<p>Of course, the unpleasant reality is most of us have to suffer a long time to gain competence. But perhaps this site will help you suffer a little less.</p>
<h2 id="about-the-name">About the name</h2>
<p>This site is called &ldquo;Decisions &amp; Dragons,&rdquo; a name that reflects the focus on reinforcement learning (RL). &ldquo;Decisions&rdquo; represents the core goal of RL: developing agents that learn to make effective decisions. &ldquo;Dragons&rdquo; represents the perilous complexities and challenges that must be navigated in pursuit of solving the RL problem.</p>
<p>I trust you understand that there were no other motivations for this name and any similarities it has with other titles is purely coincidental.</p>
<h2 id="how-i-will-update-the-site">How I will update the site</h2>
<p>At the time of launch, I populated this site with answers to frequently asked questions that I&rsquo;ve encountered and addressed in the past. I&rsquo;ve also taken this opportunity to expand on those previous answers to address follow up questions I received and to take advantage of the freedom of presentation this site affords.</p>
<p>Moving forward, I will continue to curate and share my responses to new and emerging questions, as well as revisit and refine my previous answers as needed.</p>
<p>Occasionally, I may also use this platform to share opinion pieces on RL and AI more broadly, although I am less sure of this direction. This site is still a work in progress &ndash; we&rsquo;ll see how it goes.</p>
<h2 id="about-me">About me</h2>
<p>I&rsquo;m James MacGlashan. If you want to ask me RL questions, the best place is either on <a href="https://twitter.com/jmac_ai">Twitter</a>, or
on the <a href="https://discord.gg/rn7J7W4F">Reinforcement Learning Discord server</a>.</p>
<p>I received my PhD in computer science from the University of Maryland, Balitmore County in 2013 where I
worked on reinforcement learning. I then moved on to a postdoctoral position at Brown University, where I continued to work on reinforcement learning.
Following my postdoc, I joined the startup Cogitai, where we worked to build reinforcement learning and
continual learning as a service. Cogitai was eventually acquired by Sony and we formed game AI team at <a href="https://ai.sony/">Sony AI</a>, where I
continue to work on reinforcement learning.</p>
<p>Despite all these years working on reinforcement learning, I have shockingly failed to solve it.</p>
<p>Fortunately, it hasn&rsquo;t all been bad news for the field. RL methods have vastly improved
and I&rsquo;ve played a role in bringining reinforcement learning to products with
<a href="https://www.gran-turismo.com/us/gran-turismo-sophy/">GT Sophy</a> &ndash; an RL agent that outraced the best racers in the game Gran Turismo Sport. GT Sophy was subsequently adapted to be a racing opponent in Gran Turismo 7 that you can race against today!</p>
<p>We&rsquo;re continuing to work on exciting reinforcement learning applications and problems at Sony AI and I hope we can help
turn reinforcement learning into a robust technology that can be more broadly used. Perhaps one that is less
fraught with dragons.</p>

    
  </div>

  <footer>
    <div style="text-align: center;">

</div>
  </footer>
</body>
</html>
